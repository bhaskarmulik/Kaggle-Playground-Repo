# Rough work

- There are rows with the same profession as the name. We need to remove these
- Check whether there are enough records to train the model
- Make sure to use redundancy for drop function
- Dealing with missing vals:
  - Create a temp df with no missing values
  - We can then analyse this data to make a simple regression model for the profession corresponding to the missing value
  - We also need to check correlations too

#### Thinking of using a embedding model for profession

Here is a step-by-step plan to achieve this:

- Prepare the Data: Convert the 'Profession' column to a categorical type and then to integer codes.
- Create an Embedding Layer: Define an embedding layer in your neural network to learn the embeddings for the 'Profession' feature.
- Train the Neural Network: Train the neural network with the embedding layer included.

#### Dealing with missing values

##### **Advanced Techniques for Dealing with Missing Values**

###### 1. **Predictive Modeling (Imputation Using ML Models)**

* **Method** : Use machine learning algorithms to predict the missing values based on other features in the dataset.
* **Steps** :

1. Treat the feature with missing values as the target variable.
2. Train a regression (for numerical data) or classification model (for categorical data) using other features as predictors.
3. Predict missing values using the trained model.

* **Algorithms** : Random Forest, Gradient Boosting (XGBoost, LightGBM), K-Nearest Neighbors, etc.
* **Advantages** :
* Leverages relationships between variables.
* Handles both numerical and categorical data effectively.
* **Disadvantages** :
* Computationally intensive.
* Requires a separate model for each feature with missing values.

---

###### 2. **K-Nearest Neighbors (KNN) Imputation**

* **Method** : For each missing value, find the k-nearest rows (using a distance metric like Euclidean or cosine distance) and use their values to impute.
* **Advantages** :
* Captures local relationships in the data.
* **Disadvantages** :
* Computationally expensive for large datasets.
* Sensitive to the choice of k and distance metric.

---

###### 3. **Multivariate Imputation by Chained Equations (MICE)**

* **Method** : Iteratively predicts missing values for each feature based on all other features in the dataset using regression models.
* **Advantages** :
* Captures multivariate relationships.
* Produces multiple imputations for uncertainty estimation.
* **Disadvantages** :
* Computationally intensive.
* Requires careful tuning of iteration parameters
