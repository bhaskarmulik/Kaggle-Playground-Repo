# Rough work

- There are rows with the same profession as the name. We need to remove these
- Check whether there are enough records to train the model
- Make sure to use redundancy for drop function
- Dealing with missing vals:
  - Create a temp df with no missing values
  - We can then analyse this data to make a simple regression model for the profession corresponding to the missing value
  - We also need to check correlations too
- While cleaning the dataset, make sure that

# Research

## Dealing with categorical values

#### Thinking of using a embedding model for profession

Here is a step-by-step plan to achieve this:

- Prepare the Data: Convert the 'Profession' column to a categorical type and then to integer codes.
- Create an Embedding Layer: Define an embedding layer in your neural network to learn the embeddings for the 'Profession' feature.
- Train the Neural Network: Train the neural network with the embedding layer included.

#### Dealing with missing values

##### **Advanced Techniques for Dealing with Missing Values**

###### 1. **Predictive Modeling (Imputation Using ML Models)**

* **Method** : Use machine learning algorithms to predict the missing values based on other features in the dataset.
* **Steps** :

1. Treat the feature with missing values as the target variable.
2. Train a regression (for numerical data) or classification model (for categorical data) using other features as predictors.
3. Predict missing values using the trained model.

* **Algorithms** : Random Forest, Gradient Boosting (XGBoost, LightGBM), K-Nearest Neighbors, etc.
* **Advantages** :
  * Leverages relationships between variables.
  * Handles both numerical and categorical data effectively.
* **Disadvantages** :
  * Computationally intensive.
  * Requires a separate model for each feature with missing values.

---

###### 2. **K-Nearest Neighbors (KNN) Imputation**

* **Method** : For each missing value, find the k-nearest rows (using a distance metric like Euclidean or cosine distance) and use their values to impute.
* **Advantages** :
  * Captures local relationships in the data.
* **Disadvantages** :
  * Computationally expensive for large datasets.
  * Sensitive to the choice of k and distance metric.

---

###### 3. **Multivariate Imputation by Chained Equations (MICE)**

* **Method** : Iteratively predicts missing values for each feature based on all other features in the dataset using regression models.
* **Advantages** :
  * Captures multivariate relationships.
  * Produces multiple imputations for uncertainty estimation.
* **Disadvantages** :
  * Computationally intensive.
  * Requires careful tuning of iteration parameters.

---

###### 4. **Matrix Factorization (e.g., SVD, PCA)**

* **Method** : Uses techniques like Singular Value Decomposition (SVD) or Principal Component Analysis (PCA) to approximate the data matrix and fill in missing values.
* **Advantages** :
  * Suitable for large-scale data.
  * Preserves global structure.
* **Disadvantages** :
  * Assumes linear relationships between variables.
  * May not work well if missing values are sparse.

---

###### 5. **Clustering-Based Imputation**

* **Method** : Use clustering algorithms (e.g., K-means, DBSCAN) to group similar data points and impute missing values based on cluster averages or modes.
* **Advantages** :
  * Captures local patterns.
* **Disadvantages** :
  * Requires pre-clustering of the data.
  * Sensitive to the quality of clustering.

---

###### 8. **Bayesian Imputation**

* **Method** : Use Bayesian models to impute missing values by treating them as latent variables and sampling from the posterior distribution.
* **Advantages** :

  * Accounts for uncertainty in imputations.
* **Disadvantages** :

  * Computationally intensive.
  * Requires expertise in Bayesian modeling

###### 9. Target encoding

![1732646509953](image/rw/1732646509953.png)

The distribution of the encoded `Zipcode` feature roughly follows the distribution of the actual ratings, meaning that movie-watchers differed enough in their ratings from zipcode to zipcode that our target encoding was able to capture useful information.

MEstimatorEncoder class from scikit-learn can be used

###### 10. Categorical value embedding

https://cpa-analytics.github.io/embedding-encoder-intro/
